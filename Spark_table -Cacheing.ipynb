{"cells": [{"cell_type": "code", "execution_count": 17, "id": "42f293b3-01ad-4b95-999e-abb97e94eb9f", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\nspark=SparkSession.builder \\\n.appName(\"DaataFrame_Cache\") \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 18, "id": "c7c0fa6e-7df3-41c5-8937-46afb3274aef", "metadata": {"tags": []}, "outputs": [], "source": "customers_schema='customers_id INT ,name STRING,city String,state STRING,country STRING,registrartion_date STRING,is_active BOOLEAN'"}, {"cell_type": "code", "execution_count": 19, "id": "047bd452-da20-4b7a-8416-dacc2a43caca", "metadata": {"tags": []}, "outputs": [], "source": "customers_df=spark.read.format('csv').schema(customers_schema).load('/data/customers10mb.csv')"}, {"cell_type": "code", "execution_count": 20, "id": "ba139e82-85c2-42a2-8548-287dbe8e5761", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n25/04/20 04:20:19 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `spark_catalog`.`default`.`customers10mb` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n25/04/20 04:20:19 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"}], "source": "customers_df.write.format('csv').saveAsTable('default.customers10mb')"}, {"cell_type": "code", "execution_count": 21, "id": "c99479b9-1dfd-4d11-b391-1dae1d6fe6cc", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------------+---------+-------+\n|          col_name|data_type|comment|\n+------------------+---------+-------+\n|      customers_id|      int|   NULL|\n|              name|   string|   NULL|\n|              city|   string|   NULL|\n|             state|   string|   NULL|\n|           country|   string|   NULL|\n|registrartion_date|   string|   NULL|\n|         is_active|  boolean|   NULL|\n+------------------+---------+-------+\n\n"}], "source": "spark.sql('describe customers10mb').show()"}, {"cell_type": "code", "execution_count": 22, "id": "7dd8b6df-7984-4f96-bc4a-05dbf94d5667", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------+-------------------------------------------------------+-------+\n|col_name                    |data_type                                              |comment|\n+----------------------------+-------------------------------------------------------+-------+\n|customers_id                |int                                                    |NULL   |\n|name                        |string                                                 |NULL   |\n|city                        |string                                                 |NULL   |\n|state                       |string                                                 |NULL   |\n|country                     |string                                                 |NULL   |\n|registrartion_date          |string                                                 |NULL   |\n|is_active                   |boolean                                                |NULL   |\n|                            |                                                       |       |\n|# Detailed Table Information|                                                       |       |\n|Catalog                     |spark_catalog                                          |       |\n|Database                    |default                                                |       |\n|Table                       |customers10mb                                          |       |\n|Owner                       |root                                                   |       |\n|Created Time                |Sun Apr 20 04:20:20 UTC 2025                           |       |\n|Last Access                 |UNKNOWN                                                |       |\n|Created By                  |Spark 3.5.3                                            |       |\n|Type                        |MANAGED                                                |       |\n|Provider                    |csv                                                    |       |\n|Statistics                  |42445 bytes                                            |       |\n|Location                    |hdfs://cluster-06ba-m/user/hive/warehouse/customers10mb|       |\n+----------------------------+-------------------------------------------------------+-------+\nonly showing top 20 rows\n\n"}], "source": "spark.sql('describe extended customers10mb').show(truncate=False)"}, {"cell_type": "code", "execution_count": 24, "id": "501dddf3-a187-4271-b9b0-33bea9b0b6ef", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 2 items\n-rw-r--r--   2 root hadoop          0 2025-04-20 04:20 /user/hive/warehouse/customers10mb/_SUCCESS\n-rw-r--r--   2 root hadoop      42445 2025-04-20 04:20 /user/hive/warehouse/customers10mb/part-00000-3db61a0a-2545-4b61-84d5-76f1b34489ae-c000.csv\n"}], "source": "!hadoop fs -ls /user/hive/warehouse/customers10mb"}, {"cell_type": "code", "execution_count": 28, "id": "af1e5eaa-580b-4a15-8e22-b89d25fbb74e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+---------------+---------+-----------+----------+------------------+---------+\n|customers_id|           name|     city|      state|   country|registrartion_date|is_active|\n+------------+---------------+---------+-----------+----------+------------------+---------+\n|        NULL|        Kolkata|Telangana|      India|2023-07-11|              True|     NULL|\n|      169004|Customer_169004|   Mumbai|West Bengal|     India|        2023-03-02|     true|\n|      169005|Customer_169005|Bangalore|  Telangana|     India|        2023-01-16|     true|\n|      169006|Customer_169006|    Delhi| Tamil Nadu|     India|        2023-11-30|    false|\n|      169007|Customer_169007|    Delhi|West Bengal|     India|        2023-01-29|    false|\n+------------+---------------+---------+-----------+----------+------------------+---------+\n\n"}], "source": "spark.sql('select * from customers10mb limit 5').show()"}, {"cell_type": "code", "execution_count": 29, "id": "c707f7a1-6362-44a9-8bc6-ab363affa76f", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------+-------------------------------------------------------+-------+\n|col_name                    |data_type                                              |comment|\n+----------------------------+-------------------------------------------------------+-------+\n|customers_id                |int                                                    |NULL   |\n|name                        |string                                                 |NULL   |\n|city                        |string                                                 |NULL   |\n|state                       |string                                                 |NULL   |\n|country                     |string                                                 |NULL   |\n|registrartion_date          |string                                                 |NULL   |\n|is_active                   |boolean                                                |NULL   |\n|                            |                                                       |       |\n|# Detailed Table Information|                                                       |       |\n|Catalog                     |spark_catalog                                          |       |\n|Database                    |default                                                |       |\n|Table                       |customers10mb                                          |       |\n|Owner                       |root                                                   |       |\n|Created Time                |Sun Apr 20 04:20:20 UTC 2025                           |       |\n|Last Access                 |UNKNOWN                                                |       |\n|Created By                  |Spark 3.5.3                                            |       |\n|Type                        |MANAGED                                                |       |\n|Provider                    |csv                                                    |       |\n|Statistics                  |42445 bytes                                            |       |\n|Location                    |hdfs://cluster-06ba-m/user/hive/warehouse/customers10mb|       |\n+----------------------------+-------------------------------------------------------+-------+\nonly showing top 20 rows\n\n"}], "source": "spark.sql('describe extended customers10mb').show(truncate=False)  ##will take less time"}, {"cell_type": "code", "execution_count": null, "id": "95c367e1-6c08-4569-b555-184aa2bc2495", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "045abce7-2fd6-4243-be91-2cec9711ebc5", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 30, "id": "96cb1d25-2e3b-4bc6-823c-adbaa71735e4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+\n|count(8)|\n+--------+\n|     670|\n+--------+\n\n"}], "source": "spark .sql('select count(8) from customers10mb').show() ## will take some time reading whole data"}, {"cell_type": "code", "execution_count": 34, "id": "16f5aee9-81b9-4034-853e-a7f860ecfdb3", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/20 04:40:26 WARN CacheManager: Asked to cache already cached data.\n"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": "df = spark.read.csv(\"/data/customers10mb.csv\", header=True, inferSchema=True)\ndf.createOrReplaceTempView(\"customer10mb\")\nspark.sql(\"cache table customer10mb\")\n## Eager Cache"}, {"cell_type": "code", "execution_count": null, "id": "9cfbfda6-51aa-4b15-9ab7-8554cf9fe039", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}