{"cells": [{"cell_type": "code", "execution_count": 1, "id": "6074c370-ed09-498c-9fae-b1e1f92cc85a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/16 12:45:07 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nspark=SparkSession.builder \\\n.appName('Spark SQL') \\\n.enableHiveSupport() \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 2, "id": "7a9ca749-a830-4e0d-b018-4cf54b378589", "metadata": {"tags": []}, "outputs": [], "source": "data=[\n    (1,\"Alice\",\"Mumbai\",\"2023-03-15\",True),\n    (2,\"Bob\",\"Calcutta\",\"2024-05-19\",False),\n    (3,\"Charlie\",\"Banglore\",\"2024-07-28\",True)\n]\ncolumns=[\"customer_id\",\"name\",\"city\",\"registration_date\",\"is_active\"]\ndf=spark.createDataFrame(data,columns)"}, {"cell_type": "code", "execution_count": 3, "id": "d6179961-32db-4dd6-82f7-63e56c817e01", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n"}, {"name": "stdout", "output_type": "stream", "text": "+---------+\n|namespace|\n+---------+\n|  default|\n+---------+\n\n"}], "source": "spark.sql('show databases').show()"}, {"cell_type": "code", "execution_count": 4, "id": "b7336e99-b122-4be6-b996-841bee50190b", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "DataFrame[]"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql('use default')"}, {"cell_type": "code", "execution_count": null, "id": "2768867f-01eb-4b21-8ba1-c6d9614e57a4", "metadata": {"scrolled": true, "tags": []}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 5, "id": "b12a0954-113e-4f8d-83bc-c11e67560b15", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+--------------------+-----------+\n|namespace|           tableName|isTemporary|\n+---------+--------------------+-----------+\n|  default|           customers|      false|\n|  default|customers_persistent|      false|\n+---------+--------------------+-----------+\n\n"}], "source": "spark.sql('show tables').show()"}, {"cell_type": "code", "execution_count": 6, "id": "50896883-bffb-4b43-8cc4-3e4f2c9172b6", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+----------+---------+-----------+-------+-----------------+---------+\n|customer_id|      name|     city|      state|country|registration_date|is_active|\n+-----------+----------+---------+-----------+-------+-----------------+---------+\n|          0|Customer_0|     Pune|Maharashtra|  India|       2023-06-29|    false|\n|          1|Customer_1|Bangalore| Tamil Nadu|  India|       2023-12-07|     true|\n|          2|Customer_2|Hyderabad|    Gujarat|  India|       2023-10-27|     true|\n|          3|Customer_3|Bangalore|  Karnataka|  India|       2023-10-17|    false|\n|          4|Customer_4|Ahmedabad|  Karnataka|  India|       2023-03-14|    false|\n+-----------+----------+---------+-----------+-------+-----------------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql('select * from customers_persistent limit 5').show()"}, {"cell_type": "code", "execution_count": 7, "id": "84defee7-bcdd-4166-9065-f760d6523849", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "DataFrame[]"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql('''\nCREATE TABLE IF NOT EXISTS customers(\ncustomer_id INT,\nname STRING,\ncity STRING,\nregistration_date String,\nis_active BOOLEAN\n) USING CSV\n''')"}, {"cell_type": "code", "execution_count": 8, "id": "a0c2ff1b-94d9-4f95-b97d-f23e0398648b", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+--------------------+-----------+\n|namespace|           tableName|isTemporary|\n+---------+--------------------+-----------+\n|  default|           customers|      false|\n|  default|customers_persistent|      false|\n+---------+--------------------+-----------+\n\n"}], "source": "spark.sql('show tables ').show()"}, {"cell_type": "code", "execution_count": 9, "id": "40dfa53e-395b-41f7-af71-cfe4f9ddf160", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------+---------------------------------------------------------+-------+\n|col_name                    |data_type                                                |comment|\n+----------------------------+---------------------------------------------------------+-------+\n|customer_id                 |int                                                      |NULL   |\n|name                        |string                                                   |NULL   |\n|city                        |string                                                   |NULL   |\n|registration_date           |string                                                   |NULL   |\n|is_active                   |boolean                                                  |NULL   |\n|                            |                                                         |       |\n|# Detailed Table Information|                                                         |       |\n|Catalog                     |spark_catalog                                            |       |\n|Database                    |default                                                  |       |\n|Table                       |customers                                                |       |\n|Owner                       |root                                                     |       |\n|Created Time                |Wed Apr 16 12:36:24 UTC 2025                             |       |\n|Last Access                 |UNKNOWN                                                  |       |\n|Created By                  |Spark 3.5.3                                              |       |\n|Type                        |MANAGED                                                  |       |\n|Provider                    |CSV                                                      |       |\n|Location                    |hdfs://cluster-06ba-m/user/hive/warehouse/customers      |       |\n|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       |       |\n|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat         |       |\n|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat|       |\n+----------------------------+---------------------------------------------------------+-------+\n\n"}], "source": "spark.sql('describe extended customers').show(truncate=False)"}, {"cell_type": "code", "execution_count": 12, "id": "f75237a6-b239-4085-ac72-3afe28d119b5", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/16 12:48:08 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"}], "source": "df.write.mode('overwrite').saveAsTable('default.customers')"}, {"cell_type": "code", "execution_count": 13, "id": "85613931-6418-4647-9cb2-60fcd105911a", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 2:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-------+--------+-----------------+---------+\n|customer_id|   name|    city|registration_date|is_active|\n+-----------+-------+--------+-----------------+---------+\n|          1|  Alice|  Mumbai|       2023-03-15|     true|\n|          2|    Bob|Calcutta|       2024-05-19|    false|\n|          3|Charlie|Banglore|       2024-07-28|     true|\n+-----------+-------+--------+-----------------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql('select * from customers limit 5').show()"}, {"cell_type": "code", "execution_count": 15, "id": "b4d1981c-b4ee-431f-96ab-7f5ef9a31b1e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "++\n||\n++\n++\n\n"}], "source": "spark.sql('''\ndrop table if exists customers_persistent\n''').show()"}, {"cell_type": "code", "execution_count": 16, "id": "9d500bc6-e9e5-426b-b428-bcfc1e837787", "metadata": {"tags": []}, "outputs": [], "source": "## table is defined by two thing \n## data and metadata\n## data is stored in hdfs(/hive/warehouse)\n## metadata is on hive metadata \n## when drop delete table it delete metadata and data"}, {"cell_type": "code", "execution_count": 17, "id": "f00bde0e-8d64-4240-93fa-ca4e7a885a2f", "metadata": {"tags": []}, "outputs": [], "source": "spark.stop()"}, {"cell_type": "code", "execution_count": null, "id": "2633cc79-9950-4da1-b385-1afc3fc005ec", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}