{"cells": [{"cell_type": "code", "execution_count": 3, "id": "a2c5dfa2-d634-443e-848c-9d0c9ad0a26f", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\nspark=SparkSession.builder \\\n.appName('Spark SQL Managed vs External') \\\n.enableHiveSupport() \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 5, "id": "3f987f5e-d944-4094-8199-d9e6fce57ca0", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+---------+-----------+-------+-----------------+---------+\n|customer_id|      name|     city|      state|country|registration_date|is_active|\n+-----------+----------+---------+-----------+-------+-----------------+---------+\n|          0|Customer_0|     Pune|Maharashtra|  India|       2023-06-29|    false|\n|          1|Customer_1|Bangalore| Tamil Nadu|  India|       2023-12-07|     true|\n|          2|Customer_2|Hyderabad|    Gujarat|  India|       2023-10-27|     true|\n|          3|Customer_3|Bangalore|  Karnataka|  India|       2023-10-17|    false|\n|          4|Customer_4|Ahmedabad|  Karnataka|  India|       2023-03-14|    false|\n+-----------+----------+---------+-----------+-------+-----------------+---------+\nonly showing top 5 rows\n\n"}], "source": "df=spark.read\\\n.format('csv')\\\n.option('inferSchema',\"True\")\\\n.option('header','True')\\\n.load('/data/first_100_customers.csv')\ndf.show(5)"}, {"cell_type": "code", "execution_count": 6, "id": "a945dad7-74a2-4db3-811b-078c50e839e1", "metadata": {"tags": []}, "outputs": [], "source": "df.createOrReplaceTempView('temp_customers')"}, {"cell_type": "code", "execution_count": 7, "id": "ae305aa2-7d2f-4bda-97e7-de0067035740", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+----------+---------+-----------+-------+-----------------+---------+\n|customer_id|      name|     city|      state|country|registration_date|is_active|\n+-----------+----------+---------+-----------+-------+-----------------+---------+\n|          0|Customer_0|     Pune|Maharashtra|  India|       2023-06-29|    false|\n|          1|Customer_1|Bangalore| Tamil Nadu|  India|       2023-12-07|     true|\n|          2|Customer_2|Hyderabad|    Gujarat|  India|       2023-10-27|     true|\n|          3|Customer_3|Bangalore|  Karnataka|  India|       2023-10-17|    false|\n|          4|Customer_4|Ahmedabad|  Karnataka|  India|       2023-03-14|    false|\n+-----------+----------+---------+-----------+-------+-----------------+---------+\n\n"}], "source": "spark.sql('select* from temp_customers limit 5').show()"}, {"cell_type": "raw", "id": "74183765-e6cf-421b-aabf-69e4beeb5996", "metadata": {}, "source": "spark.sql('show tables').show()"}, {"cell_type": "code", "execution_count": 8, "id": "17748d2b-362f-4479-bd9a-3898fa533bf4", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n"}, {"name": "stdout", "output_type": "stream", "text": "+---------+--------------+-----------+\n|namespace|     tableName|isTemporary|\n+---------+--------------+-----------+\n|         |temp_customers|       true|\n+---------+--------------+-----------+\n\n"}], "source": "spark.sql('show tables').show()"}, {"cell_type": "code", "execution_count": 9, "id": "286854bd-2557-477d-8896-8accb99a4071", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/16 15:08:03 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n25/04/16 15:08:03 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n                                                                                \r"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql('create table managed_customers as select * from temp_customers')"}, {"cell_type": "code", "execution_count": 10, "id": "007ee6be-0e23-489c-83f0-8fa7775f6140", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------+----------------------------------+-------+\n|col_name                    |data_type                         |comment|\n+----------------------------+----------------------------------+-------+\n|customer_id                 |int                               |NULL   |\n|name                        |string                            |NULL   |\n|city                        |string                            |NULL   |\n|state                       |string                            |NULL   |\n|country                     |string                            |NULL   |\n|registration_date           |date                              |NULL   |\n|is_active                   |boolean                           |NULL   |\n|                            |                                  |       |\n|# Detailed Table Information|                                  |       |\n|Catalog                     |spark_catalog                     |       |\n|Database                    |default                           |       |\n|Table                       |managed_customers                 |       |\n|Owner                       |root                              |       |\n|Created Time                |Wed Apr 16 15:08:03 UTC 2025      |       |\n|Last Access                 |UNKNOWN                           |       |\n|Created By                  |Spark 3.5.3                       |       |\n|Type                        |MANAGED                           |       |\n|Provider                    |hive                              |       |\n|Table Properties            |[transient_lastDdlTime=1744816085]|       |\n|Statistics                  |5424 bytes                        |       |\n+----------------------------+----------------------------------+-------+\nonly showing top 20 rows\n\n"}], "source": "spark.sql('describe extended managed_customers').show(truncate=False)"}, {"cell_type": "code", "execution_count": 11, "id": "46904ebf-5a09-46cd-9c12-85d6115775d6", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 1 items\ndrwxr-xr-x   - root hadoop          0 2025-04-16 15:08 /user/hive/warehouse/managed_customers\n"}], "source": "!hadoop fs -ls /user/hive/warehouse/"}, {"cell_type": "code", "execution_count": null, "id": "eb24d8ac-1327-43d3-8987-ff3ce963df13", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "01d0316d-1aee-48df-b776-8865c944d966", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "67f8cab0-fe4f-48d9-9877-6ffebf151e67", "metadata": {"tags": []}, "source": "## External Table"}, {"cell_type": "code", "execution_count": 13, "id": "21e0cf58-ee79-424d-ba08-d0f21acef66e", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "customer_id,name,city,state,country,registration_date,is_active\n0,Customer_0,Pune,Maharashtra,India,2023-06-29,False\n1,Customer_1,Bangalore,Tamil Nadu,India,2023-12-07,True\n2,Customer_2,Hyderabad,Gujarat,India,2023-10-27,True\n3,Customer_3,Bangalore,Karnataka,India,2023-10-17,False\n4,Customer_4,Ahmedabad,Karnataka,India,2023-03-14,False\n5,Customer_5,Hyderabad,Karnataka,India,2023-07-28,False\n6,Customer_6,Pune,Delhi,India,2023-08-29,False\n7,Customer_7,Ahmedabad,West Bengal,India,2023-12-28,True\n8,Customer_8,Pune,Karnataka,India,2023-06-22,True\n9,Customer_9,Mumbai,Telangana,India,2023-01-05,True\n10,Customer_10,Pune,Gujarat,India,2023-08-05,True\n11,Customer_11,Delhi,West Bengal,India,2023-08-02,False\n12,Customer_12,Chennai,Gujarat,India,2023-11-21,False\n13,Customer_13,Chennai,Karnataka,India,2023-11-06,True\n14,Customer_14,Hyderabad,Tamil Nadu,India,2023-02-07,False\n15,Customer_15,Mumbai,Gujarat,India,2023-03-02,True\n16,Customer_16,Chennai,Karnataka,India,2023-04-05,False\n17,Customer_17,Hyderabad,West Bengal,India"}], "source": "!hadoop fs -head /data/external_data/first_100_customers.csv\n"}, {"cell_type": "code", "execution_count": null, "id": "dfd686e8-6caf-415a-8e15-5bd949895b15", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 1, "id": "d7e3cf37-5e95-43af-8c3c-2e0d9de02047", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n25/04/16 15:12:35 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `spark_catalog`.`default`.`external_customers_2` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n25/04/16 15:12:35 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"}, {"data": {"text/plain": "DataFrame[]"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql('''\ncreate external table if not exists external_customers_2(\ncustomer_id INT,\nname STRING,\ncity STRING,\nstate string,\ncountry string, \nregistration_date String,\nis_active BOOLEAN\n)\nusing csv\nlocation'/data/external_data'\n''')\n"}, {"cell_type": "code", "execution_count": 2, "id": "ab25e0d0-a165-46fd-9c0b-e7f28de5bad6", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------------------------+--------------------------------------------------+-------+\n|col_name                    |data_type                                         |comment|\n+----------------------------+--------------------------------------------------+-------+\n|customer_id                 |int                                               |NULL   |\n|name                        |string                                            |NULL   |\n|city                        |string                                            |NULL   |\n|state                       |string                                            |NULL   |\n|country                     |string                                            |NULL   |\n|registration_date           |string                                            |NULL   |\n|is_active                   |boolean                                           |NULL   |\n|                            |                                                  |       |\n|# Detailed Table Information|                                                  |       |\n|Catalog                     |spark_catalog                                     |       |\n|Database                    |default                                           |       |\n|Table                       |external_customers_2                              |       |\n|Owner                       |root                                              |       |\n|Created Time                |Wed Apr 16 15:12:36 UTC 2025                      |       |\n|Last Access                 |UNKNOWN                                           |       |\n|Created By                  |Spark 3.5.3                                       |       |\n|Type                        |EXTERNAL                                          |       |\n|Provider                    |csv                                               |       |\n|Location                    |hdfs://cluster-06ba-m/data/external_data          |       |\n|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe|       |\n+----------------------------+--------------------------------------------------+-------+\nonly showing top 20 rows\n\n"}], "source": "spark.sql('describe extended external_customers_2').show(truncate=False)"}, {"cell_type": "code", "execution_count": 29, "id": "1f968712-cf1e-4943-b492-6b933ce4e032", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": "DataFrame[]"}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": "spark.sql(\"DROP TABLE IF EXISTS external_customers\")\n"}, {"cell_type": "code", "execution_count": 3, "id": "7c60dbdc-0288-4880-92f6-e1cd07ed005f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+---------------+---------+-----------+----------+-----------------+---------+\n|customer_id|           name|     city|      state|   country|registration_date|is_active|\n+-----------+---------------+---------+-----------+----------+-----------------+---------+\n|       NULL|        Kolkata|Telangana|      India|2023-07-11|             True|     NULL|\n|     169004|Customer_169004|   Mumbai|West Bengal|     India|       2023-03-02|     true|\n|     169005|Customer_169005|Bangalore|  Telangana|     India|       2023-01-16|     true|\n|     169006|Customer_169006|    Delhi| Tamil Nadu|     India|       2023-11-30|    false|\n|     169007|Customer_169007|    Delhi|West Bengal|     India|       2023-01-29|    false|\n+-----------+---------------+---------+-----------+----------+-----------------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "spark.sql('select * from external_customers_2 limit 5').show()"}, {"cell_type": "code", "execution_count": 4, "id": "62f95c59-d5a5-4d78-b7c0-928f56c332f2", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 1 items\ndrwxr-xr-x   - root hadoop          0 2025-04-16 15:08 /user/hive/warehouse/managed_customers\n"}], "source": "!hadoop fs -ls /user/hive/warehouse/"}, {"cell_type": "code", "execution_count": 5, "id": "aa63d55b-2117-41be-9e6a-becfd1ccadba", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "++\n||\n++\n++\n\n"}], "source": "spark.sql('drop table managed_customers').show()    ## metadata and data both will be deleted"}, {"cell_type": "code", "execution_count": 33, "id": "834ffaca-10ad-42b4-b5c7-025abeb7dcba", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "++\n||\n++\n++\n\n"}], "source": "##lets talk about external table\nspark.sql('drop table external_customers_2').show()"}, {"cell_type": "code", "execution_count": 34, "id": "44c9ff4c-9d1d-4b61-98b1-74a807e32f3f", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 1 items\n-rw-r--r--   2 root hadoop      42451 2025-04-16 14:12 /data/external_data/customers.csv\n"}], "source": "!hadoop fs -ls /data/external_data"}, {"cell_type": "code", "execution_count": null, "id": "15cd0cf2-5d4e-49c8-973d-7ba4a0e56512", "metadata": {"tags": []}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "b48b7c27-eea4-4135-a784-8afb22d54fda", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}